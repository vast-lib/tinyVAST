[{"path":"/articles/spatial.html","id":"percent-deviance-explained","dir":"Articles","previous_headings":"","what":"Percent deviance explained","title":"Spatial modeling","text":"can compute deviance residuals percent-deviance explained: can compare PDE reported mgcv comparison shows using SPDE method tinyVAST results higher percent-deviance-explained. reduced performance splines relative SPDE method presumably arises due reduced rank spline basis expansion, better match Matern function (SPDE method) relative true (simulated) exponential semivariogram. easy confirm mgcv tinyVAST give (essentially) identical PDE switching tinyVAST use bivariate spline space.","code":"R1 = sum( residuals(out, type=\"deviance\")^2 )  # tinyVAST null model with just a single intercept null = tinyVAST( data = Data,                  formula = n ~ 1 ) R0 = sum( residuals(null, type=\"deviance\")^2 )  # Percent deviance explained 1 - R1/R0 #> [1] 0.5051624 start_time = Sys.time() mygam = gam( n ~ s(w) + s(x,y), data=Data ) # Sys.time() - start_time #> Time difference of 0.03410411 secs summary(mygam)$dev.expl #> [1] 0.3517756 out_reduced = tinyVAST( data = Data,                         formula = n ~ s(w) + s(x,y) ) R1_reduced = sum( residuals(out_reduced, type=\"deviance\")^2 ) 1 - R1_reduced/R0 #> [1] 0.3497174"},{"path":"/articles/spatial.html","id":"visualize-spatial-response","dir":"Articles","previous_headings":"","what":"Visualize spatial response","title":"Spatial modeling","text":"tinyVAST standard predict function: used compute spatial response   can also compute marginal effect cyclic confounder","code":"predict(out, newdata=data.frame(x=1, y=1, time=1, w=1, var=\"n\") ) #> [1] 0.3649899 # Prediction grid pred = outer( seq(1,n_x,len=51),               seq(1,n_y,len=51),               FUN=\\(x,y) predict(out,newdata=data.frame(x=x,y=y,w=1,time=1,var=\"n\")) ) image( x=seq(1,n_x,len=51), y=seq(1,n_y,len=51), z=pred, main=\"Predicted response\" ) # True value image( x=1:n_x, y=1:n_y, z=matrix(Data$z,ncol=n_y), main=\"True response\" ) library(pdp)  # approx = TRUE gives effects for average of other covariates library(lattice) #library(visreg)  # compute partial dependence plot Partial = partial( object = out,                    pred.var = \"w\",                    pred.fun = \\(object,newdata) predict(object,newdata),                    train = Data,                    approx = TRUE )  # Lattice plots as default option plotPartial( Partial )"},{"path":"/articles/spatial_factor_analysis.html","id":"spatial-factor-analysis","dir":"Articles","previous_headings":"","what":"Spatial factor analysis","title":"Spatial factor analysis","text":"first explore ability specify two latent variables five manifest variables. start simulate two spatial latent variables, project via simulated loadings matrix, simulate Tweedie response manifest variable: can inspect simulated loadings matrix True loadings specify model expected tinyVAST: can compare true loadings (rotated optimize comparison): Rotated true loadings estimated loadings can compared estimated true loadings matrices: Rotated estimated loadings can specify model ensuring residual spatial variation also captured: can compared estimated true loadings matrices: Rotated estimated loadings full rank","code":"# Simulate settings theta_xy = 0.4 n_x = n_y = 10 n_c = 5 rho = 0.8 resid_sd = 0.5  # Simulate GMRFs R_s = exp(-theta_xy * abs(outer(1:n_x, 1:n_y, FUN=\"-\")) ) R_ss = kronecker(X=R_s, Y=R_s) delta_fs = mvtnorm::rmvnorm(n_c, sigma=R_ss )  # L_cf = matrix( rnorm(n_c^2), nrow=n_c ) L_cf[,3:5] = 0 L_cf = L_cf + resid_sd * diag(n_c)  # d_cs = L_cf %*% delta_fs dimnames(L_cf) = list( paste0(\"Var \", 1:nrow(L_cf)),                        paste0(\"Factor \", 1:ncol(L_cf)) ) knitr::kable( L_cf,               digits=2, caption=\"True loadings\") # Shape into longform data-frame and add error Data = data.frame( expand.grid(species=1:n_c, x=1:n_x, y=1:n_y),                    \"var\"=\"logn\", \"z\"=exp(as.vector(d_cs)) ) Data$n = tweedie::rtweedie( n=nrow(Data), mu=Data$z, phi=0.5, power=1.5 ) mean(Data$n==0) #> [1] 0.03  # make mesh mesh = fm_mesh_2d( Data[,c('x','y')] )  # sem = \"   f1 -> 1, l1   f1 -> 2, l2   f1 -> 3, l3   f1 -> 4, l4   f1 -> 5, l5   f2 -> 2, l6   f2 -> 3, l7   f2 -> 4, l8   f2 -> 5, l9   f1 <-> f1, NA, 1   f2 <-> f2, NA, 1   1 <-> 1, NA, 0   2 <-> 2, NA, 0   3 <-> 3, NA, 0   4 <-> 4, NA, 0   5 <-> 5, NA, 0 \"  # fit model out = tinyVAST( sem = sem,            data = Data,            formula = n ~ 0 + factor(species),            spatial_graph = mesh,            family = tweedie(),            variables = c( \"f1\", \"f2\", 1:n_c ),            space_columns = c(\"x\",\"y\"),            variable_column = \"species\",            time_column = \"time\",            distribution_column = \"dist\",            control = tinyVASTcontrol(gmrf=\"proj\") ) out #> $call #> tinyVAST(formula = n ~ 0 + factor(species), data = Data, sem = sem,  #>     family = tweedie(), space_columns = c(\"x\", \"y\"), spatial_graph = mesh,  #>     time_column = \"time\", variable_column = \"species\", variables = c(\"f1\",  #>         \"f2\", 1:n_c), distribution_column = \"dist\", control = tinyVASTcontrol(gmrf = \"proj\")) #>  #> $opt #> $opt$par #>     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     theta_z  #>  0.07570783 -0.02014888  0.22318277  0.14728087 -0.26514652  0.68016356  #>     theta_z     theta_z     theta_z     theta_z     theta_z     theta_z  #>  0.68285927  0.31701846  0.52123769  0.14819781  0.51873790 -0.31998633  #>     theta_z     theta_z   log_sigma   log_sigma   log_kappa  #>  0.23601680 -0.21613586 -0.52205331  0.21851154 -0.26761196  #>  #> $opt$objective #> [1] 631.3721 #>  #> $opt$convergence #> [1] 0 #>  #> $opt$iterations #> [1] 71 #>  #> $opt$evaluations #> function gradient  #>       84       71  #>  #> $opt$message #> [1] \"relative convergence (4)\" #>  #>  #> $sdrep #> sdreport(.) result #>              Estimate Std. Error #> alpha_j    0.07570783 0.31850774 #> alpha_j   -0.02014888 0.39763412 #> alpha_j    0.22318277 0.21847161 #> alpha_j    0.14728087 0.27057852 #> alpha_j   -0.26514652 0.14638317 #> theta_z    0.68016356 0.11510781 #> theta_z    0.68285927 0.15773444 #> theta_z    0.31701846 0.10358197 #> theta_z    0.52123769 0.10914344 #> theta_z    0.14819781 0.09200614 #> theta_z    0.51873790 0.13709521 #> theta_z   -0.31998633 0.10049164 #> theta_z    0.23601680 0.10640963 #> theta_z   -0.21613586 0.09652980 #> log_sigma -0.52205331 0.06761637 #> log_sigma  0.21851154 0.13313019 #> log_kappa -0.26761196 0.21030826 #> Maximum gradient component: 0.002233932  #>  #> $run_time #> Time difference of 1.264592 secs Lrot_cf = rotate_pca( L_cf )$L_tf dimnames(Lrot_cf) = list( paste0(\"Var \", 1:nrow(Lrot_cf)),                        paste0(\"Factor \", 1:ncol(Lrot_cf)) ) knitr::kable( Lrot_cf,               digits=2, caption=\"Rotated true loadings\") # Extract and rotate estimated loadings Lhat_cf = matrix( 0, nrow=n_c, ncol=2 ) Lhat_cf[lower.tri(Lhat_cf,diag=TRUE)] = as.list(out$sdrep, what=\"Estimate\")$theta_z Lhat_cf = rotate_pca( L_tf=Lhat_cf, order=\"decreasing\" )$L_tf #> Warning in sqrt(Eigen$values): NaNs produced dimnames(Lhat_cf) = list( paste0(\"Var \", 1:nrow(Lhat_cf)),                        paste0(\"Factor \", 1:ncol(Lhat_cf)) ) knitr::kable( Lhat_cf,               digits=2, caption=\"Rotated estimated loadings\" ) # sem = \"   f1 -> 1, l1   f1 -> 2, l2   f1 -> 3, l3   f1 -> 4, l4   f1 -> 5, l5   f2 -> 2, l6   f2 -> 3, l7   f2 -> 4, l8   f2 -> 5, l9   f1 <-> f1, NA, 1   f2 <-> f2, NA, 1   1 <-> 1, sd_resid   2 <-> 2, sd_resid   3 <-> 3, sd_resid   4 <-> 4, sd_resid   5 <-> 5, sd_resid \"  # fit model out = tinyVAST( sem = sem,            data = Data,            formula = n ~ 0 + factor(species),            spatial_graph = mesh,            family = list( \"obs\"=tweedie() ),            variables = c( \"f1\", \"f2\", 1:n_c ),            space_columns = c(\"x\",\"y\"),            variable_column = \"species\",            time_column = \"time\",            distribution_column = \"dist\",            control = tinyVASTcontrol(gmrf=\"proj\") )  # Extract and rotate estimated loadings Lhat_cf = matrix( 0, nrow=n_c, ncol=2 ) Lhat_cf[lower.tri(Lhat_cf,diag=TRUE)] = as.list(out$sdrep, what=\"Estimate\")$theta_z #> Warning in Lhat_cf[lower.tri(Lhat_cf, diag = TRUE)] = as.list(out$sdrep, : #> number of items to replace is not a multiple of replacement length Lhat_cf = rotate_pca( L_tf=Lhat_cf, order=\"decreasing\" )$L_tf #> Warning in sqrt(Eigen$values): NaNs produced dimnames(Lhat_cf) = list( paste0(\"Var \", 1:nrow(Lhat_cf)),                        paste0(\"Factor \", 1:ncol(Lhat_cf)) ) knitr::kable( Lhat_cf,               digits=2, caption=\"Rotated estimated loadings with full rank\" )"},{"path":"/articles/web_only/age_composition_expansion.html","id":"expanding-age-composition-data","dir":"Articles > Web_only","previous_headings":"","what":"Expanding age-composition data","title":"Age composition expansion","text":"start, load sampling data undergone first-stage expansion. arises primary sampling unit includes secondary subsampling ages, subsampled proporrtion--age primary unit expanded total abundance primary sample: Next, construct various inputs tinyVAST run model log-linked Tweedie distribution single linear predictor: model fitted, apply area-expansion epsilon bias-correction method predict abundance--age, convert proportion: Finally, can compare estimates package VAST. Estimates differ somewhat VAST used delta-gamma distribution spatio-temporal variation two linear predictors, also used different mesh.","code":"data( bering_sea_pollock_ages )  # subset to Years 2010-2023 (to speed up the example) Data = subset( bering_sea_pollock_ages, Year >= 2010 )  # Add Year-_Age interaction Data$Age = factor( paste0(\"Age_\",Data$Age) ) Data$Year_Age = interaction( Data$Year, Data$Age )  # Project data to UTM Data = st_as_sf( Data,                     coords = c('Lon','Lat'),                    crs = st_crs(4326) ) Data = st_transform( Data,                          crs = st_crs(\"+proj=utm +zone=2 +units=km\") ) # Add UTM coordinates as columns X & Y Data = cbind( st_drop_geometry(Data), st_coordinates(Data) ) # adds different variances for each age sem = \"\"  # Constant AR1 spatio-temporal term across ages # and adds different variances for each age dsem = \"   Age_1 -> Age_1, 1, lag1   Age_2 -> Age_2, 1, lag1   Age_3 -> Age_3, 1, lag1   Age_4 -> Age_4, 1, lag1   Age_5 -> Age_5, 1, lag1   Age_6 -> Age_6, 1, lag1   Age_7 -> Age_7, 1, lag1   Age_8 -> Age_8, 1, lag1   Age_9 -> Age_9, 1, lag1   Age_10 -> Age_10, 1, lag1   Age_11 -> Age_11, 1, lag1   Age_12 -> Age_12, 1, lag1   Age_13 -> Age_13, 1, lag1   Age_14 -> Age_14, 1, lag1   Age_15 -> Age_15, 1, lag1 \"  mesh = fm_mesh_2d( loc = Data[,c(\"X\",\"Y\")],                             cutoff = 50 ) control = tinyVASTcontrol( getsd = FALSE,                            profile = c(\"alpha_j\"),                              trace = 0 ) family = list(   Age_1 = tweedie(),   Age_2 = tweedie(),   Age_3 = tweedie(),   Age_4 = tweedie(),   Age_5 = tweedie(),    Age_6 = tweedie(),   Age_7 = tweedie(),   Age_8 = tweedie(),   Age_9 = tweedie(),   Age_10 = tweedie(),   Age_11 = tweedie(),   Age_12 = tweedie(),   Age_13 = tweedie(),   Age_14 = tweedie(),   Age_15 = tweedie()      )  #Data$Year = factor(Data$Year) myfit = tinyVAST(   data = Data,   formula = Catch_KG ~ 0 + Year_Age,   sem = sem,   dsem = dsem,   family = family,   space_column = c(\"X\", \"Y\"),    variable_column = \"Age\",   time_column = \"Year\",   distribution_column = \"Age\",   spatial_graph = mesh,   control = control ) # Get shapefile for survey extent data( bering_sea )  # Make extrapolation grid based on shapefile bering_sea = st_transform( bering_sea,                             st_crs(\"+proj=utm +zone=2 +units=km\") ) grid = st_make_grid( bering_sea, n=c(50,50) ) grid = st_intersection( grid, bering_sea ) grid = st_make_valid( grid ) loc_gz = st_coordinates(st_centroid( grid ))  # Get area for extrapolation grid library(units) areas = set_units(st_area(grid), \"hectares\") #  / 100^2 # Hectares  # Get abundance N_jz = expand.grid( Age=myfit$internal$variables, Year=sort(unique(Data$Year)) ) N_jz = cbind( N_jz, \"Biomass\"=NA, \"SE\"=NA ) for( j in seq_len(nrow(N_jz)) ){   if( N_jz[j,'Age']==1 ){     message( \"Integrating \", N_jz[j,'Year'], \" \", N_jz[j,'Age'], \": \", Sys.time() )   }   if( is.na(N_jz[j,'Biomass']) ){     newdata = data.frame( loc_gz, Year=N_jz[j,'Year'], Age=N_jz[j,'Age'])       newdata$Year_Age = paste( newdata$Year, newdata$Age, sep=\".\" )     # Area-expansion     index1 = integrate_output( myfit,                     area = areas,                     newdata = newdata,                     apply.epsilon = TRUE,                     bias.correct = FALSE,                     intern = TRUE )     N_jz[j,'Biomass'] = index1[3] / 1e9   } } N_ct = array( N_jz$Biomass, dim=c(length(myfit$internal$variables),length(unique(Data$Year))),               dimnames=list(myfit$internal$variables,sort(unique(Data$Year))) ) N_ct = N_ct / outer( rep(1,nrow(N_ct)), colSums(N_ct) ) # Load VAST results for same data data(bering_sea_pollock_vast) myvast = bering_sea_pollock_vast rownames(myvast) = 1:15  # Reformat tinyVAST output with same dimnames mytiny = N_ct rownames(mytiny) = 1:15  # longvast = cbind( expand.grid(dimnames(myvast)), \"p\"=as.numeric(myvast), \"method\"=\"VAST\" ) longtiny = cbind( expand.grid(dimnames(mytiny)), \"p\"=as.numeric(mytiny), \"method\"=\"tinyVAST\" ) long = rbind( longvast, longtiny )  library(ggplot2) ggplot( data=long, aes(x=Var2, y=p, col=method) ) +   facet_grid( rows=vars(Var1), scales=\"free\" ) +   geom_point( ) +   scale_y_log10()"},{"path":"/articles/web_only/condition.html","id":"abundance-weighted-expansion","dir":"Articles > Web_only","previous_headings":"","what":"Abundance-weighted expansion","title":"Condition and density","text":"explore output, can plot output using survey extent:","code":"# Extract shapefile region = condition_and_density$eastern_bering_sea  # make extrapolation-grid sf_grid = st_make_grid( region, cellsize=c(0.5,0.5) ) sf_grid = st_intersection( sf_grid, region ) sf_grid = st_make_valid( sf_grid )  # grid_coords = st_coordinates( st_centroid(sf_grid) ) areas_km2 = st_area( sf_grid ) / 1e6  # Condition in  newdata = data.frame( \"Lat\" = grid_coords[,'Y'],                        \"Lon\" = grid_coords[,'X'],                       \"Year\" = 1982,                       \"Type\" = \"Condition\",                       #\"Year_Type\" = \"1982_Condition\",                       \"log_length\" = 0 ) cond_1982 = predict(fit, newdata=newdata, what=\"p_g\")  # Repeat for density newdata2 = newdata newdata2$Type = \"Biomass\" #newdata2$Year_Type = \"1982_Biomass\" dens_1982 = predict(fit, newdata=newdata2, what=\"p_g\")  # Plot on map plot_grid = st_sf( sf_grid,                      \"Condition.1982\" = cond_1982,                     \"Density.1982\" = dens_1982 )  plot( plot_grid )"},{"path":"/articles/web_only/condition.html","id":"density-weighted-condition","dir":"Articles > Web_only","previous_headings":"","what":"Density-weighted condition","title":"Condition and density","text":"Finally, can calculate density-weighted condition","code":"#  expand_data = rbind( newdata2, newdata ) W_gz = cbind( c(as.numeric(areas_km2),rep(0,length(areas_km2))), 0 ) V_gz = cbind( rep(c(0,3),each=length(areas_km2)), seq_along(areas_km2)-1 )  # cond_tz = data.frame( \"Year\"=1998:2016, \"Est\"=NA, \"SE\"=NA ) for( yearI in seq_len(nrow(cond_tz)) ){   expand_data[,'Year'] = cond_tz[yearI,\"Year\"]   out = integrate_output( fit,                            newdata = expand_data,                           V_gz = V_gz,                           W_gz = W_gz,                            bias.correct = TRUE )    cond_tz[yearI,c(\"Est\",\"SE\")] = out[c(\"Estimate\",\"Std. Error\")] }  # plot time-series ggplot( cond_tz ) +   geom_line( aes(x=Year, y=Est) ) +   geom_ribbon( aes(x=Year, ymin=Est-SE, ymax=Est+SE), alpha=0.2 )"},{"path":"/articles/web_only/empirical_orthogonal_functions.html","id":"empirical-orthogonal-function-eof-analysis","dir":"Articles > Web_only","previous_headings":"","what":"Empirical Orthogonal Function (EOF) analysis","title":"Empirical orthogonal functions","text":"start, reformat data September Sea ice concentrations: Next, construct various inputs tinyVAST Finally, can extract, rotate, plot dominant modes variability associated spatial responses:","code":"data( sea_ice ) library(sf) library(rnaturalearth)  # project data sf_ice = st_as_sf( sea_ice, coords = c(\"lon\",\"lat\") ) st_crs(sf_ice) = \"+proj=longlat +datum=WGS84\" sf_ice = st_transform( sf_ice,                       crs=st_crs(\"+proj=laea +lat_0=90 +lon_0=-30 +units=km\") )  # sf_pole = st_point( c(0,90) ) sf_pole = st_sfc( sf_pole, crs=\"+proj=longlat +datum=WGS84\" ) sf_pole = st_transform( sf_pole, crs=st_crs(sf_ice) ) sf_pole = st_buffer( sf_pole, dist=3000 ) sf_ice = st_intersection( sf_ice, sf_pole ) #> Warning: attribute variables are assumed to be spatially constant throughout all geometries  Data = data.frame( st_drop_geometry(sf_ice),               st_coordinates(sf_ice),               var = \"Ice\" ) n_eof = 2 dsem = make_eof_ram( variables = \"Ice\",                      times = sort(unique(Data[,'year'])),                      n_eof = 2,                      standard_deviations = 0 ) mesh = fm_mesh_2d( Data[,c('X','Y')], cutoff=1.5 )  # fit model out = tinyVAST( dsem = dsem,            sem = \"\",            data = as.data.frame(Data),            formula = ice_concentration ~ 1,            spatial_graph = mesh,            space_column = c(\"X\",\"Y\"),            variable_column = \"var\",            time_column = \"year\",            distribution_column = \"dist\",            times = c(paste0(\"EOF_\",seq_len(n_eof)), sort(unique(Data[,'year']))),            control = tinyVASTcontrol( profile=\"alpha_j\",                                       gmrf_parameterization=\"projection\") ) # Country shapefiles for plotting sf_maps = ne_countries( return=\"sf\", scale=\"medium\", continent=c(\"north america\",\"europe\",\"asia\") ) sf_maps = st_transform( sf_maps, crs=st_crs(sf_ice) ) sf_maps = st_union( sf_maps )  # Shapefile for water sf_water = st_difference( st_as_sfc(st_bbox(sf_maps)), sf_maps )  # Create extrapolation grid cellsize = 50 sf_grid = st_make_grid( sf_pole, cellsize=cellsize ) # Restrict to water grid_i = st_intersects( sf_water, sf_grid ) sf_grid = sf_grid[ unique(unlist(grid_i)) ] # Restrict to 3000 km from North Pole grid_i = st_intersects( sf_pole, sf_grid ) sf_grid = sf_grid[ unique(unlist(grid_i)) ]  # newdata = data.frame( st_coordinates(st_centroid(sf_grid)),                       var = \"Ice\" )  # Extract loadings L_tf = matrix( 0, nrow=length(unique(Data$year)), ncol=2,                dimnames=list(unique(Data$year),c(\"EOF_1\",\"EOF_2\")) ) L_tf[lower.tri(L_tf,diag=TRUE)] = out$opt$par[names(out$opt$par)==\"beta_z\"]  # Extract factor-responses EOF1_g = predict( out, cbind(newdata, year=\"EOF_1\"), what=\"pepsilon_g\" ) EOF2_g = predict( out, cbind(newdata, year=\"EOF_2\"), what=\"pepsilon_g\" ) omega_g = predict( out, cbind(newdata, year=\"EOF_2\"), what=\"pomega_g\" )  # Rotate responses and loadings rotated_results = rotate_pca( L_tf=L_tf, x_sf=cbind(EOF1_g,EOF2_g), order=\"decreasing\" ) #> Warning in sqrt(Eigen$values): NaNs produced EOF1_g = rotated_results$x_sf[,1] EOF2_g = rotated_results$x_sf[,2] L_tf = rotated_results$L_tf  # Plot on map sf_plot = st_sf( sf_grid, \"EOF1_g\"=EOF1_g, \"EOF2_g\"=EOF2_g, \"omega_g\"=omega_g ) par(mfrow=c(2,2), oma=c(2,2,0,0) ) plot( sf_plot[,'EOF1_g'], reset=FALSE, key.pos=NULL, border=NA )   plot( st_geometry(sf_maps), add=TRUE, border=NA, col=\"grey\" ) plot( sf_plot[,'EOF2_g'], reset=FALSE, key.pos=NULL, border=NA )   plot( st_geometry(sf_maps), add=TRUE, border=NA, col=\"grey\" ) plot( sf_plot[,'omega_g'], reset=FALSE, key.pos=NULL, border=NA )   plot( st_geometry(sf_maps), add=TRUE, border=NA, col=\"grey\" ) matplot( y=L_tf, x=unique(Data$year), type=\"l\",          col=viridisLite::viridis(n_eof), lwd=2, lty=\"solid\" )   legend( \"top\", ncol=n_eof, legend=paste0(\"EOF\",1:n_eof),           fill=viridisLite::viridis(n_eof) )"},{"path":"/articles/web_only/VAST.html","id":"spatio-temporal-autoregressive-model","dir":"Articles > Web_only","previous_headings":"","what":"Spatio-temporal autoregressive model","title":"Vector autoregressive spatio-temporal models","text":"first explore ability specify first-order autoregressive spatio-temporal process: estimated values beta_z correspond simulated value rho spatial_sd. can compare true densities: estimated densities: scatterplot shows highly correlated: can also use DHARMa package visualize simulation residuals: can calculate area-weighted total abundance compare true value: Next, compare current version VAST sdmTMB models similar runtimes","code":"# Simulate settings theta_xy = 0.4 n_x = n_y = 10 n_t = 15 rho = 0.8 spatial_sd = 0.5  # Simulate GMRFs R_s = exp(-theta_xy * abs(outer(1:n_x, 1:n_y, FUN=\"-\")) ) V_ss = spatial_sd^2*kronecker(R_s, R_s) d = mvtnorm::rmvnorm(n_t, sigma=V_ss )  # Project through time and add mean for( t in seq_len(n_t) ){   if(t>1) d[t,] = rho*d[t-1,] + d[t,] } #d = d + 0.5  # Shape into longform data-frame and add error Data = data.frame( expand.grid(time=1:n_t, x=1:n_x, y=1:n_y), \"var\"=\"logn\", z=exp(as.vector(d))) Data$n = tweedie::rtweedie( n=nrow(Data), mu=Data$z, phi=0.5, power=1.5 ) mean(Data$n==0) #> [1] 0.046  # make mesh mesh = fm_mesh_2d( Data[,c('x','y')] )  # fit model mytinyVAST = tinyVAST( dsem = \"logn -> logn, 1, rho\",            data = Data,            formula = n ~ 0 + factor(time),            spatial_graph = mesh,            family = tweedie() ) mytinyVAST #> $call #> tinyVAST(formula = n ~ 0 + factor(time), data = Data, dsem = \"logn -> logn, 1, rho\",  #>     family = tweedie(), spatial_graph = mesh) #>  #> $opt #> $opt$par #>     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j     alpha_j  #> -0.08323604 -0.13549104 -0.10579217 -0.14499114 -0.37823869 -0.21633307 -0.41489959 -0.67168423 -0.49463135 -0.13968720  0.14836187 -0.21516693 -0.20120058  0.16887045  #>     alpha_j      beta_z      beta_z   log_sigma   log_sigma   log_kappa  #>  0.30040122  0.81229112  0.40988915 -0.64868475  0.04394543  0.07228542  #>  #> $opt$objective #> [1] 1717.689 #>  #> $opt$convergence #> [1] 0 #>  #> $opt$iterations #> [1] 77 #>  #> $opt$evaluations #> function gradient  #>      107       77  #>  #> $opt$message #> [1] \"relative convergence (4)\" #>  #>  #> $sdrep #> sdreport(.) result #>              Estimate Std. Error #> alpha_j   -0.08323604 0.15196456 #> alpha_j   -0.13549104 0.18670340 #> alpha_j   -0.10579217 0.20529851 #> alpha_j   -0.14499114 0.21780791 #> alpha_j   -0.37823869 0.22691800 #> alpha_j   -0.21633307 0.23026450 #> alpha_j   -0.41489959 0.23456777 #> alpha_j   -0.67168423 0.23833635 #> alpha_j   -0.49463135 0.23869331 #> alpha_j   -0.13968720 0.23733095 #> alpha_j    0.14836187 0.23640201 #> alpha_j   -0.21516693 0.23873590 #> alpha_j   -0.20120058 0.23979214 #> alpha_j    0.16887045 0.23708655 #> alpha_j    0.30040122 0.23660035 #> beta_z     0.81229112 0.03708631 #> beta_z     0.40988915 0.03291043 #> log_sigma -0.64868475 0.05422114 #> log_sigma  0.04394543 0.07275797 #> log_kappa  0.07228542 0.10755269 #> Maximum gradient component: 0.006315957  #>  #> $run_time #> Time difference of 19.30986 secs library(sf) data_wide = reshape( Data[,c('x','y','time','z')],                      direction = \"wide\", idvar = c('x','y'), timevar = \"time\") sf_data = st_as_sf( data_wide, coords=c(\"x\",\"y\")) sf_grid = sf::st_make_grid( sf_data ) sf_plot = st_sf(sf_grid, st_drop_geometry(sf_data) ) plot(sf_plot, max.plot=n_t ) Data$z_hat = predict(mytinyVAST) data_wide = reshape( Data[,c('x','y','time','z_hat')],                      direction = \"wide\", idvar = c('x','y'), timevar = \"time\") sf_data = st_as_sf( data_wide, coords=c(\"x\",\"y\")) sf_plot = st_sf(sf_grid, st_drop_geometry(sf_data) ) plot(sf_plot, max.plot=n_t ) plot( x=Data$z, y=Data$z_hat ) # simulate new data conditional on fixed and random effects y_ir = replicate( n = 100,             expr = mytinyVAST$obj$simulate()$y_i )  # res = DHARMa::createDHARMa( simulatedResponse = y_ir,                              observedResponse = Data$n,                              fittedPredictedResponse = fitted(mytinyVAST) ) plot(res) # Predicted sample-weighted total (Est = sapply( seq_len(n_t),    FUN=\\(t) integrate_output(mytinyVAST, newdata=subset(Data,time==t)) )) #>                           [,1]       [,2]       [,3]       [,4]      [,5]       [,6]      [,7]      [,8]      [,9]      [,10]     [,11]      [,12]     [,13]     [,14] #> Estimate             97.164902  96.643634  98.362458 101.517620 84.760587  97.538110 77.520820 59.565797 75.752785 113.562128 159.66734 120.156809 137.80745 192.64174 #> Std. Error            7.194683   7.216494   7.309313   7.572241  6.643419   7.406226  6.207919  5.090533  6.144821   8.454587  11.09945   9.107852  10.39448  13.68245 #> Est. (bias.correct) 102.324275 102.850496 105.043004 108.373176 90.604659 104.258111 83.102278 64.065173 81.166864 120.921460 169.20673 127.519259 145.78500 203.55063 #> Std. (bias.correct)         NA         NA         NA         NA        NA         NA        NA        NA        NA         NA        NA         NA        NA        NA #>                         [,15] #> Estimate            187.86973 #> Std. Error           12.88189 #> Est. (bias.correct) 200.54754 #> Std. (bias.correct)        NA  # True (latent) sample-weighted total (True = tapply( Data$z, INDEX=Data$time, FUN=sum )) #>         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15  #>  99.21643 100.10603 101.66846 109.52622  85.76973 100.97116  80.99847  68.60738  85.39974 119.62380 147.41437 122.00580 158.26179 200.56813 203.37545  # Index = data.frame( time=seq_len(n_t), t(Est), True ) Index$low = Index[,'Est...bias.correct.'] - 1.96*Index[,'Std..Error'] Index$high = Index[,'Est...bias.correct.'] + 1.96*Index[,'Std..Error']  # library(ggplot2) #> Warning: package 'ggplot2' was built under R version 4.3.3 ggplot(Index, aes(time, Estimate)) +   geom_ribbon(aes(ymin = low,                   ymax = high),    # shadowing cnf intervals               fill = \"lightgrey\") +   geom_line( color = \"black\",             linewidth = 1) +   geom_point( aes(time, True), color = \"red\" ) settings = make_settings( purpose=\"index3\",                           n_x = n_x*n_y,                           Region = \"Other\",                           bias.correct = FALSE,                           use_anisotropy = FALSE ) settings$FieldConfig['Epsilon','Component_1'] = 0 settings$FieldConfig['Omega',] = 0 settings$RhoConfig['Epsilon2'] = 4 settings$RhoConfig['Beta1'] = 3 settings$ObsModel = c(10,2)  # Run VAST myVAST = fit_model( settings=settings,                  Lat_i = Data[,'y'],                  Lon_i = Data[,'x'],                  t_i = Data[,'time'],                  b_i = Data[,'n'],                  a_i = rep(1,nrow(Data)),                  observations_LL = cbind(Lat=Data[,'y'],Lon=Data[,'x']),                  grid_dim_km = c(100,100),                  newtonsteps = 0,                  loopnum = 1,                  control = list(eval.max = 10000, iter.max = 10000, trace = 0) ) myVAST #> fit_model(.) result #> $par #>       beta1_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft  #>    -0.58930073     0.51556564     0.46458138     0.49054919     0.46815476     0.22995172     0.39666650     0.19322490    -0.07072448     0.11680345     0.47101097  #>       beta2_ft       beta2_ft       beta2_ft       beta2_ft       beta2_ft   L_epsilon2_z      logkappa2 Epsilon_rho2_f      logSigmaM  #>     0.77135921     0.40831814     0.42839450     0.79998255     0.91170568     0.49266123    -4.30062279     0.85035927     0.10422305  #>  #> $objective #> [1] 1738.337 #>  #> $iterations #> [1] 6 #>  #> $evaluations #> function gradient  #>       12        7  #>  #> $time_for_MLE #> Time difference of 0.9828639 secs #>  #> $max_gradient #> [1] 0.0005696325 #>  #> $Convergence_check #> [1] \"The model is likely not converged\" #>  #> $number_of_coefficients #>  Total  Fixed Random  #>   2060     20   2040  #>  #> $AIC #> [1] 3516.675 #>  #> $diagnostics #>             Param starting_value     Lower         MLE     Upper final_gradient #> 1        beta1_ft    -0.58930212      -Inf -0.58930073       Inf  -2.567181e-04 #> 2        beta2_ft     0.51556572      -Inf  0.51556564       Inf   7.261656e-06 #> 3        beta2_ft     0.46458084      -Inf  0.46458138       Inf  -1.594548e-05 #> 4        beta2_ft     0.49055254      -Inf  0.49054919       Inf   2.243884e-04 #> 5        beta2_ft     0.46815189      -Inf  0.46815476       Inf  -2.138462e-04 #> 6        beta2_ft     0.22994937      -Inf  0.22995172       Inf  -1.954432e-04 #> 7        beta2_ft     0.39666757      -Inf  0.39666650       Inf   7.243535e-05 #> 8        beta2_ft     0.19322636      -Inf  0.19322490       Inf   1.265298e-04 #> 9        beta2_ft    -0.07072352      -Inf -0.07072448       Inf   8.136321e-05 #> 10       beta2_ft     0.11680233      -Inf  0.11680345       Inf  -9.143842e-05 #> 11       beta2_ft     0.47100948      -Inf  0.47101097       Inf  -1.191484e-04 #> 12       beta2_ft     0.77135985      -Inf  0.77135921       Inf   3.399154e-05 #> 13       beta2_ft     0.40831866      -Inf  0.40831814       Inf   3.723723e-05 #> 14       beta2_ft     0.42839437      -Inf  0.42839450       Inf  -2.700504e-05 #> 15       beta2_ft     0.79997987      -Inf  0.79998255       Inf  -1.674651e-04 #> 16       beta2_ft     0.91170842      -Inf  0.91170568       Inf   1.970479e-04 #> 17   L_epsilon2_z     0.49266062      -Inf  0.49266123       Inf  -3.367341e-04 #> 18      logkappa2    -4.30062172 -6.214608 -4.30062279 -3.565449   1.066371e-04 #> 19 Epsilon_rho2_f     0.85035618 -0.990000  0.85035927  0.990000  -5.696325e-04 #> 20      logSigmaM     0.10422369      -Inf  0.10422305 10.000000   8.907767e-05 #>  #> $SD #> sdreport(.) result #>                   Estimate Std. Error #> beta1_ft       -0.58930073 0.05080467 #> beta2_ft        0.51556564 0.14414517 #> beta2_ft        0.46458138 0.17371753 #> beta2_ft        0.49054919 0.19200615 #> beta2_ft        0.46815476 0.20433941 #> beta2_ft        0.22995172 0.21476798 #> beta2_ft        0.39666650 0.21934844 #> beta2_ft        0.19322490 0.22481460 #> beta2_ft       -0.07072448 0.22973074 #> beta2_ft        0.11680345 0.23059098 #> beta2_ft        0.47101097 0.22964742 #> beta2_ft        0.77135921 0.22895295 #> beta2_ft        0.40831814 0.23199191 #> beta2_ft        0.42839450 0.23305156 #> beta2_ft        0.79998255 0.23091833 #> beta2_ft        0.91170568 0.23072494 #> L_epsilon2_z    0.49266123 0.04727208 #> logkappa2      -4.30062279 0.13652887 #> Epsilon_rho2_f  0.85035927 0.03527714 #> logSigmaM       0.10422305 0.07108160 #> Maximum gradient component: 0.0005696325  #>  #> $time_for_sdreport #> Time difference of 4.135285 secs #>  #> $time_for_run #> Time difference of 19.02913 secs library(sdmTMB) #> Warning: package 'sdmTMB' was built under R version 4.3.3 mesh = make_mesh(Data, c(\"x\",\"y\"), n_knots=n_x*n_y )  start_time = Sys.time() mysdmTMB = sdmTMB(   formula = n ~ 0 + factor(time),   data = Data,   mesh = mesh,   spatial = \"off\",   spatiotemporal = \"ar1\",   time = \"time\",   family = tweedie() ) sdmTMBtime = Sys.time() - start_time Times = c( \"tinyVAST\" = mytinyVAST$run_time,            \"VAST\" = myVAST$total_time,            \"sdmTMB\" = sdmTMBtime ) knitr::kable( cbind(\"run times (sec.)\"=Times), digits=1)"},{"path":"/articles/web_only/VAST.html","id":"delta-models","dir":"Articles > Web_only","previous_headings":"","what":"Delta models","title":"Vector autoregressive spatio-temporal models","text":"can also fit data using delta model can use DHARMa package visualize simulation residuals: can use AIC compare fit delta-model Tweedie distribution:","code":"# fit model mydelta2 = tinyVAST( data = Data,                formula = n ~ 1,                delta_options = list(                  delta_formula = ~ 0 + factor(time),                  delta_dsem = \"logn -> logn, 1, rho\"),                family = delta_lognormal(type=\"poisson-link\"),                spatial_graph = mesh )  mydelta #> Error in eval(expr, envir, enclos): object 'mydelta' not found # simulate new data conditional on fixed and random effects y_ir = replicate( n = 100,             expr = mydelta2$obj$simulate()$y_i )  # res = DHARMa::createDHARMa( simulatedResponse = y_ir,                              observedResponse = Data$n,                              fittedPredictedResponse = fitted(mydelta2) ) plot(res) knitr::kable( c(\"Tweedie\"=AIC(mytinyVAST),\"delta-lognormal\"=AIC(mydelta2)), digits=3)"},{"path":"/articles/web_only/VAST.html","id":"bivariate-spatio-temporal-autoregressive-model","dir":"Articles > Web_only","previous_headings":"","what":"Bivariate spatio-temporal autoregressive model","title":"Vector autoregressive spatio-temporal models","text":"next highlight specify bivariate spatio-temporal model cross-laggged (vector autoregressive) interaction. values beta_z correspond specified value interaction-matrix B can calculate area-weighted total abundance compare true value:","code":"# Simulate settings theta_xy = 0.2 n_x = n_y = 10 n_t = 20 B = rbind( c( 0.5, -0.25),            c(-0.1,  0.50) )  # Simulate GMRFs R = exp(-theta_xy * abs(outer(1:n_x, 1:n_y, FUN=\"-\")) ) d1 = mvtnorm::rmvnorm(n_t, sigma=0.2*kronecker(R,R) ) d2 = mvtnorm::rmvnorm(n_t, sigma=0.2*kronecker(R,R) ) d = abind::abind( d1, d2, along=3 )  # Project through time and add mean for( t in seq_len(n_t) ){   if(t>1) d[t,,] = t(B%*%t(d[t-1,,])) + d[t,,] }  # Shape into longform data-frame and add error Data = data.frame( expand.grid(time=1:n_t, x=1:n_x, y=1:n_y, \"var\"=c(\"d1\",\"d2\")), z=exp(as.vector(d))) Data$n = tweedie::rtweedie( n=nrow(Data), mu=Data$z, phi=0.5, power=1.5 )  # make mesh mesh = fm_mesh_2d( Data[,c('x','y')] )  # Define DSEM dsem = \"   d1 -> d1, 1, b11   d2 -> d2, 1, b22   d2 -> d1, 1, b21   d1 -> d2, 1, b12   d1 <-> d1, 0, var1   d2 <-> d2, 0, var1 \"  # fit model out = tinyVAST( dsem = dsem,            data = Data,            formula = n ~ 0 + var,            spatial_graph = mesh,            family = tweedie() ) out #> $call #> tinyVAST(formula = n ~ 0 + var, data = Data, dsem = dsem, family = tweedie(),  #>     spatial_graph = mesh) #>  #> $opt #> $opt$par #>      alpha_j      alpha_j       beta_z       beta_z       beta_z       beta_z       beta_z    log_sigma    log_sigma    log_kappa  #> -0.135067087 -0.050931909  0.537678546  0.471060516 -0.268664645 -0.080655519  0.355720082 -0.675048463  0.004059747 -0.566274472  #>  #> $opt$objective #> [1] 4300.721 #>  #> $opt$convergence #> [1] 0 #>  #> $opt$iterations #> [1] 45 #>  #> $opt$evaluations #> function gradient  #>       60       46  #>  #> $opt$message #> [1] \"relative convergence (4)\" #>  #>  #> $sdrep #> sdreport(.) result #>               Estimate Std. Error #> alpha_j   -0.135067087 0.11243173 #> alpha_j   -0.050931909 0.09302442 #> beta_z     0.537678546 0.06461591 #> beta_z     0.471060516 0.07549660 #> beta_z    -0.268664645 0.07225850 #> beta_z    -0.080655519 0.06157438 #> beta_z     0.355720082 0.01973953 #> log_sigma -0.675048463 0.02959907 #> log_sigma  0.004059747 0.04917005 #> log_kappa -0.566274472 0.09138031 #> Maximum gradient component: 0.002923767  #>  #> $run_time #> Time difference of 2.327756 mins # Predicted sample-weighted total Est1 = sapply( seq_len(n_t), FUN=\\(t) integrate_output(out, newdata=subset(Data,time==t & var==\"d1\")) ) Est2 = sapply( seq_len(n_t), FUN=\\(t) integrate_output(out, newdata=subset(Data,time==t & var==\"d2\")) )  # True (latent) sample-weighted total True = tapply( Data$z, INDEX=list(\"time\"=Data$time,\"var\"=Data$var), FUN=sum )  # Index = data.frame( expand.grid(dimnames(True)), \"True\"=as.vector(True) ) Index = data.frame( Index, rbind(t(Est1), t(Est2)) ) Index$low = Index[,'Est...bias.correct.'] - 1.96*Index[,'Std..Error'] Index$high = Index[,'Est...bias.correct.'] + 1.96*Index[,'Std..Error']  # library(ggplot2) ggplot(Index, aes( time, Estimate )) +   facet_grid( rows=vars(var), scales=\"free\" ) +   geom_segment(aes(y = low,                   yend = high,                   x = time,                   xend = time) ) +   geom_point( aes(x=time, y=Estimate), color = \"black\") +   geom_point( aes(x=time, y=True), color = \"red\" )"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James T. Thorson. Author, maintainer. Sean C. Anderson. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thorson JT, Ward SC, Goddard P, Rooper CN (2024). “tinyVAST: R package expressive interface specify lagged simultaneous effects multivariate spatio-temporal models.” bioRxiv, 2401.10193. doi:10.48550/arXiv.2401.10193.","code":"@Article{,   title = {tinyVAST: R package with an expressive interface to specify lagged and simultaneous effects in multivariate spatio-temporal models},   author = {James T. Thorson and Sean C. Ward and Pamela Goddard and Christopher N. Rooper},   year = {2024},   journal = {bioRxiv},   volume = {2401.10193},   doi = {10.48550/arXiv.2401.10193}, }"},{"path":"/header.html","id":null,"dir":"","previous_headings":"","what":"tinyVAST","title":"tinyVAST","text":"Multivariate spatio-temporal models using dynamic structural equations  tinyVAST R package fits multivariate spatio-temporal models using Gaussian Markov random fields represent nonseparable interactions among variables time. See preprint: Thorson, J. T., Anderson, S. C., Goddard, P., & Rooper, C. N. (2024). tinyVAST: R package expressive interface specify lagged simultaneous effects multivariate spatio-temporal models (arXiv:2401.10193). arXiv. http://arxiv.org/abs/2401.10193","code":""},{"path":[]},{"path":"/index.html","id":"tinyvast","dir":"","previous_headings":"","what":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","title":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","text":"Multivariate spatio-temporal models using dynamic structural equations tinyVAST R package fits multivariate spatio-temporal models using Gaussian Markov random fields represent nonseparable interactions among variables time. See preprint: Thorson, J. T., Anderson, S. C., Goddard, P., & Rooper, C. N. (2024). tinyVAST: R package expressive interface specify lagged simultaneous effects multivariate spatio-temporal models (arXiv:2401.10193). arXiv. http://arxiv.org/abs/2401.10193","code":""},{"path":"/index.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of contents","title":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","text":"Installation Citation Related software","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","text":"tinyVAST can installed GitHub:","code":"library(devtools) install_github(\"vast-lib/tinyVAST\", dependencies = TRUE)"},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","text":"cite tinyVAST publications use: Thorson, J. T., Anderson, S. C., Goddard, P., & Rooper, C. N. (2024). tinyVAST: R package expressive interface specify lagged simultaneous effects multivariate spatio-temporal models (arXiv:2401.10193). arXiv. http://arxiv.org/abs/2401.10193","code":"citation(\"tinyVAST\")"},{"path":"/index.html","id":"related-software","dir":"","previous_headings":"","what":"Related software","title":"Vector Autoregressive Spatio-Temporal Model Using Minimal\n    Feature-Set","text":"tinyVAST builds upon many packages. includes VAST R package: Thorson, J.T. 2019. Guidance decisions using Vector Autoregressive Spatio-Temporal (VAST) package stock, ecosystem, habitat climate assessments. Fisheries Research 210: 143–161. https://doi.org/10.1016/j.fishres.2018.10.013. sdmTMB R package: Anderson, S.C., E.J. Ward, P.. English, L..K. Barnett. 2022. sdmTMB: R package fast, flexible, user-friendly generalized linear mixed effects models spatial spatiotemporal random fields. bioRxiv 2022.03.24.485545; doi: https://doi.org/10.1101/2022.03.24.485545 glmmTMB R package: Brooks, M.E., Kristensen, K., van Benthem, K.J., Magnusson, ., Berg, C.W., Nielsen, ., Skaug, H.J., Maechler, M., Bolker, B.M. 2017. glmmTMB balances speed flexibility among packages zero-inflated generalized linear mixed modeling. R Journal 9(2): 378–400. https://doi.org/10.32614/rj-2017-066. INLA inlabru can fit many models sdmTMB (many ) approximate Bayesian inference framework. mgcv can fit similar SPDE-based Gaussian random field models code included Miller et al. (2019).","code":""},{"path":"/reference/add_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Add predictions to data-list — add_predictions","title":"Add predictions to data-list — add_predictions","text":"Given user-provided newdata, expand object tmb_data include predictions corresponding new observations","code":""},{"path":"/reference/add_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add predictions to data-list — add_predictions","text":"","code":"add_predictions(object, newdata, remove_origdata = FALSE)"},{"path":"/reference/add_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add predictions to data-list — add_predictions","text":"object Output tinyVAST(). newdata New data-frame independent variables used predict response. remove_origdata Whether remove original-data allow faster evaluation. remove_origdata=TRUE eliminates information distribution random effects, combined epsilon bias-correction. WARNING:  feature experimental subject change.","code":""},{"path":"/reference/bering_sea.html","id":null,"dir":"Reference","previous_headings":"","what":"Survey domain for the eastern and northern Bering Sea surveys — bering_sea","title":"Survey domain for the eastern and northern Bering Sea surveys — bering_sea","text":"Shapefile defining spatial domain eastern northern Bering Sea bottom trawl surveys.","code":""},{"path":"/reference/bering_sea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survey domain for the eastern and northern Bering Sea surveys — bering_sea","text":"","code":"data(bering_sea)"},{"path":"/reference/bering_sea_pollock_ages.html","id":null,"dir":"Reference","previous_headings":"","what":"Survey catch-rates at age for Alaska pollock in the Eastern and Northern Bering Sea — bering_sea_pollock_ages","title":"Survey catch-rates at age for Alaska pollock in the Eastern and Northern Bering Sea — bering_sea_pollock_ages","text":"Data used demonstrate test model-based age expansion, using density= dependence corrected survey catch rates first=stage expansion bottom trawl survey ages 1-15, conducted Alaska Fisheries Science Center, including annual surveys eastern Bering Sea 1982-2019 2021-2023, well northern Bering Sea 1982/85/88/91 2010/17/18/19/21/22/23.","code":""},{"path":"/reference/bering_sea_pollock_ages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survey catch-rates at age for Alaska pollock in the Eastern and Northern Bering Sea — bering_sea_pollock_ages","text":"","code":"data(bering_sea_pollock_ages)"},{"path":"/reference/bering_sea_pollock_vast.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimated proportion-at-age for Alaska pollock using VAST — bering_sea_pollock_vast","title":"Estimated proportion-at-age for Alaska pollock using VAST — bering_sea_pollock_vast","text":"Estimated proporrtion--age Alaska pollock using package VAST, comparison output using tinyVAST.","code":""},{"path":"/reference/bering_sea_pollock_vast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimated proportion-at-age for Alaska pollock using VAST — bering_sea_pollock_vast","text":"","code":"data(bering_sea_pollock_vast)"},{"path":"/reference/classify_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify variables path — classify_variables","title":"Classify variables path — classify_variables","text":"classify_variables copied sem:::classifyVariables","code":""},{"path":"/reference/classify_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify variables path — classify_variables","text":"","code":"classify_variables(model)"},{"path":"/reference/classify_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify variables path — classify_variables","text":"model syntax structural equation model","code":""},{"path":"/reference/classify_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify variables path — classify_variables","text":"Tagged-list defining exogenous endogenous variables","code":""},{"path":"/reference/classify_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Classify variables path — classify_variables","text":"Copied package sem licence GPL (>= 2) permission John Fox","code":""},{"path":"/reference/condition_and_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Condition and density example — condition_and_density","title":"Condition and density example — condition_and_density","text":"Data used demonstrate test bivariate model morphometric condition (.e., residuals weight--length relationship) density fishes, using example provided wiki example VAST. Data doi:10.3354/meps13213","code":""},{"path":"/reference/condition_and_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Condition and density example — condition_and_density","text":"","code":"data(condition_and_density)"},{"path":"/reference/families.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional families — Families","title":"Additional families — Families","text":"Additional families compatible tinyVAST().","code":""},{"path":"/reference/families.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional families — Families","text":"","code":"delta_lognormal(link1, link2 = \"log\", type = c(\"standard\", \"poisson-link\"))  delta_gamma(link1, link2 = \"log\", type = c(\"standard\", \"poisson-link\"))"},{"path":"/reference/families.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional families — Families","text":"link1 Link first part delta/hurdle model. link2 Link second part delta/hurdle model. type Delta/hurdle family type. \"standard\" classic hurdle model. \"poisson-link\" Poisson-link delta model (Thorson 2018). link Link.","code":""},{"path":"/reference/families.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Additional families — Families","text":"list elements common standard R family objects including family, link, linkfun, linkinv. Delta/hurdle model families also elements delta (logical) type (standard vs. Poisson-link).","code":""},{"path":"/reference/families.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Additional families — Families","text":"Poisson-link delta families: Thorson, J.T. 2018. Three problems conventional delta-model biomass sampling data, computationally efficient alternative. Canadian Journal Fisheries Aquatic Sciences, 75(9), 1369-1382. doi:10.1139/cjfas-2017-0266","code":""},{"path":"/reference/families.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Additional families — Families","text":"","code":"delta_lognormal() #>  #> Family: binomial lognormal  #> Link function: log log  #>  delta_gamma() #>  #> Family: binomial Gamma  #> Link function: logit log  #>"},{"path":"/reference/integrate_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo integration for abundance — integrate_output","title":"Monte Carlo integration for abundance — integrate_output","text":"Applies Monte Carlo integration approximate area-expanded abundance","code":""},{"path":"/reference/integrate_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo integration for abundance — integrate_output","text":"","code":"integrate_output(   object,   newdata,   V_gz,   area,   W_gz,   bias.correct = TRUE,   apply.epsilon = FALSE,   intern = FALSE )"},{"path":"/reference/integrate_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo integration for abundance — integrate_output","text":"object Output tinyVAST(). newdata New data-frame independent variables used predict response. V_gz Settings expansion. area value used area-weighted expansion estimated density surface row newdata. W_gz Covariates expansion. bias.correct logical indicating bias correction applied apply.epsilon Apply epsilon bias correction? intern Laplace approximation C++ side? Passed TMB::MakeADFun().","code":""},{"path":"/reference/make_dsem_ram.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a RAM (Reticular Action Model) — make_dsem_ram","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"make_dsem_ram converts SEM arrow notation ram describing SEM parameters","code":""},{"path":"/reference/make_dsem_ram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"","code":"make_dsem_ram(   sem,   times,   variables,   covs = NULL,   quiet = FALSE,   remove_na = TRUE )"},{"path":"/reference/make_dsem_ram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"sem Specification structural equation model structure constructing space-variable interaction. sem=NULL disables space-variable interaction; see make_sem_ram(). times character vector listing set times order variables character vector listing set variables covs optional: character vector one elements, element   \tgiving string variable names, separated commas. Variances covariances   \tamong variables string added model. confirmatory   \tfactor analysis models specified via cfa, covs defaults   \tfactors model, thus specifying variances covariances among factors.   \tWarning: covs=\"x1, x2\" covs=c(\"x1\", \"x2\")   \tequivalent: covs=\"x1, x2\" specifies variance x1, variance   \tx2, covariance, covs=c(\"x1\", \"x2\") specifies   \tvariance x1 variance x2 covariance. quiet Boolean indicating whether print messages terminal remove_na Boolean indicating whether remove NA values RAM (default) . remove_NA=FALSE might useful exploration diagnostics advanced users","code":""},{"path":"/reference/make_dsem_ram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"reticular action module (RAM) describing dependencies","code":""},{"path":"/reference/make_dsem_ram.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"RAM specification using arrow--lag notation line RAM specification make_dsem_ram consists four (unquoted) entries, separated commas: 1. Arrow specification: simple formula, form -> B , equivalently, B <- regression coefficient (.e., single-headed directional arrow); <-> variance <-> B covariance (.e., double-headed bidirectional arrow). , B variable names model. name correspond observed variable, assumed latent variable. Spaces can appear freely arrow specification, can number hyphens arrows, including zero: Thus, e.g., ->B, --> B, >B legitimate equivalent. 2. Lag (using positive values): integer specifying whether linkage simultaneous (lag=0) lagged (e.g., X -> Y, 1, XtoY indicates X time T affects Y time T+1), one-headed arrows can lagged. Using positive values indicate lags matches notational convention used package dynlm. 3. Parameter name: name regression coefficient, variance, covariance specified arrow. Assigning name two arrows results equality constraint. Specifying parameter name NA produces fixed parameter. 4. Value: start value free parameter value fixed parameter. given NA (simply omitted), model provide default starting value. Lines may end comment following #. function extends code copied package sem licence GPL (>= 2) permission John Fox. Simultaneous autoregressive process simultaneous lagged effects text specifies linkages multivariate time-series model variables \\(\\mathbf X\\) dimensions \\(T \\times C\\) \\(T\\) times \\(C\\) variables. make_dsem_ram parses text build path matrix \\(\\mathbf \\Rho\\) dimensions \\(TC \\times TC\\), \\(\\rho_{k_2,k_1}\\) represents impact \\(x_{t_1,c_1}\\) \\(x_{t_2,c_2}\\), \\(k_1=T c_1+t_1\\) \\(k_2=T c_2+t_2\\).  path matrix defines simultaneous equation $$ \\mathrm{vec}(\\mathbf X) = \\mathbf \\Rho \\mathrm{vec}(\\mathbf X) + \\mathrm{vec}(\\mathbf \\Delta)$$ \\(\\mathbf \\Delta\\) matrix exogenous errors covariance \\(\\mathbf{V = \\Gamma \\Gamma}^t\\), \\(\\mathbf \\Gamma\\) Cholesky exogenous covariance.  simultaneous autoregressive (SAR) process results \\(\\mathbf X\\) covariance: $$ \\mathrm{Cov}(\\mathbf X) = \\mathbf{(- \\Rho)}^{-1} \\mathbf{\\Gamma \\Gamma}^t \\mathbf{((- \\Rho)}^{-1})^t $$ Usefully, also easy compute inverse-covariance (precision) matrix \\(\\mathbf{Q = V}^{-1}\\): $$ \\mathbf{Q} = (\\mathbf{\\Gamma}^{-1} \\mathbf{(- \\Rho)})^t \\mathbf{\\Gamma}^{-1} \\mathbf{(- \\Rho)} $$ Example: univariate first-order autoregressive model simultaneous autoregressive (SAR) process across variables times allows user specify simultaneous effects (effects among variables within year \\(T\\)) lagged effects (effects among variables among years \\(T\\)). one example, consider univariate first-order autoregressive process \\(T=4\\). independent errors.  specified passing  sem = X -> X, 1, rho; X <-> X, 0, sigma  make_dsem_ram. parsed RAM: Rows RAM heads=1 interpreted construct path matrix \\(\\mathbf \\Rho\\):   rows heads=2 interpreted construct Cholesky exogenous covariance \\(\\mathbf \\Gamma\\):   two estimated parameters \\(\\mathbf \\beta = (\\rho, \\sigma) \\). results covariance:   Similarly, arrow--lag notation can used specify SAR representing conventional structural equation model (SEM), cross-lagged (.k.. vector autoregressive) models (VAR), dynamic factor analysis (DFA), many time-series models.","code":"\\deqn{ \\mathbf \\Rho = \\begin{bmatrix}      0 & 0 & 0 & 0 \\      \\rho & 0 & 0 & 0 \\      0 & \\rho & 0 & 0 \\      0 & 0 & \\rho & 0\\      \\end{bmatrix} } \\deqn{ \\mathbf \\Gamma = \\begin{bmatrix}      \\sigma & 0 & 0 & 0 \\      0 & \\sigma & 0 & 0 \\      0 & 0 & \\sigma & 0 \\      0 & 0 & 0 & \\sigma\\      \\end{bmatrix} } \\deqn{ \\mathrm{Cov}(\\mathbf X) = \\sigma^2 \\begin{bmatrix}      1 & \\rho^1 & \\rho^2 & \\rho^3 \\      \\rho^1 & 1 & \\rho^1 & \\rho^2 \\      \\rho^2 & \\rho^1 & 1 & \\rho^1 \\      \\rho^3 & \\rho^2 & \\rho^1 & 1\\      \\end{bmatrix} }"},{"path":"/reference/make_dsem_ram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a RAM (Reticular Action Model) — make_dsem_ram","text":"","code":"# Univariate AR1 sem = \"   X -> X, 1, rho   X <-> X, 0, sigma \" make_dsem_ram( sem=sem, variables=\"X\", times=1:4 ) #> $model #>      path      lag name    start parameter first second direction #> [1,] \"X -> X\"  \"1\" \"rho\"   NA    \"1\"       \"X\"   \"X\"    \"1\"       #> [2,] \"X <-> X\" \"0\" \"sigma\" NA    \"2\"       \"X\"   \"X\"    \"2\"       #>  #> $ram #>   heads to from parameter start #> 1     1  2    1         1  <NA> #> 2     1  3    2         1  <NA> #> 3     1  4    3         1  <NA> #> 5     2  1    1         2  <NA> #> 6     2  2    2         2  <NA> #> 7     2  3    3         2  <NA> #> 8     2  4    4         2  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\"  # Univariate AR2 sem = \"   X -> X, 1, rho1   X -> X, 2, rho2   X <-> X, 0, sigma \" make_dsem_ram( sem=sem, variables=\"X\", times=1:4 ) #> $model #>      path      lag name    start parameter first second direction #> [1,] \"X -> X\"  \"1\" \"rho1\"  NA    \"1\"       \"X\"   \"X\"    \"1\"       #> [2,] \"X -> X\"  \"2\" \"rho2\"  NA    \"2\"       \"X\"   \"X\"    \"1\"       #> [3,] \"X <-> X\" \"0\" \"sigma\" NA    \"3\"       \"X\"   \"X\"    \"2\"       #>  #> $ram #>    heads to from parameter start #> 1      1  2    1         1  <NA> #> 2      1  3    2         1  <NA> #> 3      1  4    3         1  <NA> #> 5      1  3    1         2  <NA> #> 6      1  4    2         2  <NA> #> 9      2  1    1         3  <NA> #> 10     2  2    2         3  <NA> #> 11     2  3    3         3  <NA> #> 12     2  4    4         3  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\"  # Bivariate VAR sem = \"   X -> X, 1, XtoX   X -> Y, 1, XtoY   Y -> X, 1, YtoX   Y -> Y, 1, YtoY   X <-> X, 0, sdX   Y <-> Y, 0, sdY \" make_dsem_ram( sem=sem, variables=c(\"X\",\"Y\"), times=1:4 ) #> $model #>      path      lag name   start parameter first second direction #> [1,] \"X -> X\"  \"1\" \"XtoX\" NA    \"1\"       \"X\"   \"X\"    \"1\"       #> [2,] \"X -> Y\"  \"1\" \"XtoY\" NA    \"2\"       \"X\"   \"Y\"    \"1\"       #> [3,] \"Y -> X\"  \"1\" \"YtoX\" NA    \"3\"       \"Y\"   \"X\"    \"1\"       #> [4,] \"Y -> Y\"  \"1\" \"YtoY\" NA    \"4\"       \"Y\"   \"Y\"    \"1\"       #> [5,] \"X <-> X\" \"0\" \"sdX\"  NA    \"5\"       \"X\"   \"X\"    \"2\"       #> [6,] \"Y <-> Y\" \"0\" \"sdY\"  NA    \"6\"       \"Y\"   \"Y\"    \"2\"       #>  #> $ram #>    heads to from parameter start #> 1      1  2    1         1  <NA> #> 2      1  3    2         1  <NA> #> 3      1  4    3         1  <NA> #> 5      1  6    1         2  <NA> #> 6      1  7    2         2  <NA> #> 7      1  8    3         2  <NA> #> 9      1  2    5         3  <NA> #> 10     1  3    6         3  <NA> #> 11     1  4    7         3  <NA> #> 13     1  6    5         4  <NA> #> 14     1  7    6         4  <NA> #> 15     1  8    7         4  <NA> #> 17     2  1    1         5  <NA> #> 18     2  2    2         5  <NA> #> 19     2  3    3         5  <NA> #> 20     2  4    4         5  <NA> #> 21     2  5    5         6  <NA> #> 22     2  6    6         6  <NA> #> 23     2  7    7         6  <NA> #> 24     2  8    8         6  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\"  # Dynamic factor analysis with one factor and two manifest variables # (specifies a random-walk for the factor, and miniscule residual SD) sem = \"   factor -> X, 0, loadings1   factor -> Y, 0, loadings2   factor -> factor, 1, NA, 1   X <-> X, 0, NA, 0           # No additional variance   Y <-> Y, 0, NA, 0           # No additional variance \" make_dsem_ram( sem=sem, variables=c(\"X\",\"Y\",\"factor\"), times=1:4 ) #> NOTE: adding 1 variances to the model #> $model #>                                              parameter first    second   #> [1,] \"factor -> X\"       \"0\" \"loadings1\" NA  \"1\"       \"factor\" \"X\"      #> [2,] \"factor -> Y\"       \"0\" \"loadings2\" NA  \"2\"       \"factor\" \"Y\"      #> [3,] \"factor -> factor\"  \"1\" NA          \"1\" \"0\"       \"factor\" \"factor\" #> [4,] \"X <-> X\"           \"0\" NA          \"0\" \"0\"       \"X\"      \"X\"      #> [5,] \"Y <-> Y\"           \"0\" NA          \"0\" \"0\"       \"Y\"      \"Y\"      #> [6,] \"factor <-> factor\" \"0\" \"V[factor]\" NA  \"3\"       \"factor\" \"factor\" #>      direction #> [1,] \"1\"       #> [2,] \"1\"       #> [3,] \"1\"       #> [4,] \"2\"       #> [5,] \"2\"       #> [6,] \"2\"       #>  #> $ram #>    heads to from parameter start #> 1      1  1    9         1  <NA> #> 2      1  2   10         1  <NA> #> 3      1  3   11         1  <NA> #> 4      1  4   12         1  <NA> #> 5      1  5    9         2  <NA> #> 6      1  6   10         2  <NA> #> 7      1  7   11         2  <NA> #> 8      1  8   12         2  <NA> #> 9      1 10    9         0     1 #> 10     1 11   10         0     1 #> 11     1 12   11         0     1 #> 13     2  1    1         0     0 #> 14     2  2    2         0     0 #> 15     2  3    3         0     0 #> 16     2  4    4         0     0 #> 17     2  5    5         0     0 #> 18     2  6    6         0     0 #> 19     2  7    7         0     0 #> 20     2  8    8         0     0 #> 21     2  9    9         3  <NA> #> 22     2 10   10         3  <NA> #> 23     2 11   11         3  <NA> #> 24     2 12   12         3  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\"  # ARIMA(1,1,0) sem = \"   factor -> factor, 1, rho1 # AR1 component   X -> X, 1, NA, 1          # Integrated component   factor -> X, 0, NA, 1   X <-> X, 0, NA, 0         # No additional variance \" make_dsem_ram( sem=sem, variables=c(\"X\",\"factor\"), times=1:4 ) #> NOTE: adding 1 variances to the model #> $model #>                                              parameter first    second   #> [1,] \"factor -> factor\"  \"1\" \"rho1\"      NA  \"1\"       \"factor\" \"factor\" #> [2,] \"X -> X\"            \"1\" NA          \"1\" \"0\"       \"X\"      \"X\"      #> [3,] \"factor -> X\"       \"0\" NA          \"1\" \"0\"       \"factor\" \"X\"      #> [4,] \"X <-> X\"           \"0\" NA          \"0\" \"0\"       \"X\"      \"X\"      #> [5,] \"factor <-> factor\" \"0\" \"V[factor]\" NA  \"2\"       \"factor\" \"factor\" #>      direction #> [1,] \"1\"       #> [2,] \"1\"       #> [3,] \"1\"       #> [4,] \"2\"       #> [5,] \"2\"       #>  #> $ram #>    heads to from parameter start #> 1      1  6    5         1  <NA> #> 2      1  7    6         1  <NA> #> 3      1  8    7         1  <NA> #> 5      1  2    1         0     1 #> 6      1  3    2         0     1 #> 7      1  4    3         0     1 #> 9      1  1    5         0     1 #> 10     1  2    6         0     1 #> 11     1  3    7         0     1 #> 12     1  4    8         0     1 #> 13     2  1    1         0     0 #> 14     2  2    2         0     0 #> 15     2  3    3         0     0 #> 16     2  4    4         0     0 #> 17     2  5    5         2  <NA> #> 18     2  6    6         2  <NA> #> 19     2  7    7         2  <NA> #> 20     2  8    8         2  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\"  # ARIMA(0,0,1) sem = \"   factor -> X, 0, NA, 1   factor -> X, 1, rho1     # MA1 component   X <-> X, 0, NA, 0        # No additional variance \" make_dsem_ram( sem=sem, variables=c(\"X\",\"factor\"), times=1:4 ) #> NOTE: adding 1 variances to the model #> $model #>                                              parameter first    second   #> [1,] \"factor -> X\"       \"0\" NA          \"1\" \"0\"       \"factor\" \"X\"      #> [2,] \"factor -> X\"       \"1\" \"rho1\"      NA  \"1\"       \"factor\" \"X\"      #> [3,] \"X <-> X\"           \"0\" NA          \"0\" \"0\"       \"X\"      \"X\"      #> [4,] \"factor <-> factor\" \"0\" \"V[factor]\" NA  \"2\"       \"factor\" \"factor\" #>      direction #> [1,] \"1\"       #> [2,] \"1\"       #> [3,] \"2\"       #> [4,] \"2\"       #>  #> $ram #>    heads to from parameter start #> 1      1  1    5         0     1 #> 2      1  2    6         0     1 #> 3      1  3    7         0     1 #> 4      1  4    8         0     1 #> 5      1  2    5         1  <NA> #> 6      1  3    6         1  <NA> #> 7      1  4    7         1  <NA> #> 9      2  1    1         0     0 #> 10     2  2    2         0     0 #> 11     2  3    3         0     0 #> 12     2  4    4         0     0 #> 13     2  5    5         2  <NA> #> 14     2  6    6         2  <NA> #> 15     2  7    7         2  <NA> #> 16     2  8    8         2  <NA> #>  #> attr(,\"class\") #> [1] \"dsem_ram\""},{"path":"/reference/make_eof_ram.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a RAM (Reticular Action Model) — make_eof_ram","title":"Make a RAM (Reticular Action Model) — make_eof_ram","text":"make_eof_ram converts SEM arrow notation ram describing SEM parameters","code":""},{"path":"/reference/make_eof_ram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a RAM (Reticular Action Model) — make_eof_ram","text":"","code":"make_eof_ram(   times,   variables,   n_eof,   remove_na = TRUE,   standard_deviations = \"unequal\" )"},{"path":"/reference/make_eof_ram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a RAM (Reticular Action Model) — make_eof_ram","text":"times character vector listing set times order variables character vector listing set variables n_eof Number EOF modes variability estimate remove_na Boolean indicating whether remove NA values RAM (default) . remove_NA=FALSE might useful exploration diagnostics advanced users standard_deviations One \"equal\", \"unequal\", numeric vector indicating fixed values.","code":""},{"path":"/reference/make_eof_ram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a RAM (Reticular Action Model) — make_eof_ram","text":"reticular action module (RAM) describing dependencies","code":""},{"path":"/reference/make_eof_ram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a RAM (Reticular Action Model) — make_eof_ram","text":"","code":"# Two EOFs for two variables make_eof_ram( times = 2010:2020, variables = c(\"pollock\",\"cod\"), n_eof=2 ) #> $model #>      to  from parameter #> 1  2010 EOF_1         1 #> 2  2011 EOF_1         2 #> 3  2012 EOF_1         3 #> 4  2013 EOF_1         4 #> 5  2014 EOF_1         5 #> 6  2015 EOF_1         6 #> 7  2016 EOF_1         7 #> 8  2017 EOF_1         8 #> 9  2018 EOF_1         9 #> 10 2019 EOF_1        10 #> 11 2020 EOF_1        11 #> 12 2010 EOF_2        NA #> 13 2011 EOF_2        12 #> 14 2012 EOF_2        13 #> 15 2013 EOF_2        14 #> 16 2014 EOF_2        15 #> 17 2015 EOF_2        16 #> 18 2016 EOF_2        17 #> 19 2017 EOF_2        18 #> 20 2018 EOF_2        19 #> 21 2019 EOF_2        20 #> 22 2020 EOF_2        21 #>  #> $ram #>        heads to from parameter start #>   [1,]     1  3    1         1  0.01 #>   [2,]     1  4    1         2  0.01 #>   [3,]     1  5    1         3  0.01 #>   [4,]     1  6    1         4  0.01 #>   [5,]     1  7    1         5  0.01 #>   [6,]     1  8    1         6  0.01 #>   [7,]     1  9    1         7  0.01 #>   [8,]     1 10    1         8  0.01 #>   [9,]     1 11    1         9  0.01 #>  [10,]     1 12    1        10  0.01 #>  [11,]     1 13    1        11  0.01 #>  [12,]     1 16    1         1  0.01 #>  [13,]     1 17    1         2  0.01 #>  [14,]     1 18    1         3  0.01 #>  [15,]     1 19    1         4  0.01 #>  [16,]     1 20    1         5  0.01 #>  [17,]     1 21    1         6  0.01 #>  [18,]     1 22    1         7  0.01 #>  [19,]     1 23    1         8  0.01 #>  [20,]     1 24    1         9  0.01 #>  [21,]     1 25    1        10  0.01 #>  [22,]     1 26    1        11  0.01 #>  [23,]     1  4    2        12  0.01 #>  [24,]     1  5    2        13  0.01 #>  [25,]     1  6    2        14  0.01 #>  [26,]     1  7    2        15  0.01 #>  [27,]     1  8    2        16  0.01 #>  [28,]     1  9    2        17  0.01 #>  [29,]     1 10    2        18  0.01 #>  [30,]     1 11    2        19  0.01 #>  [31,]     1 12    2        20  0.01 #>  [32,]     1 13    2        21  0.01 #>  [33,]     1 17    2        12  0.01 #>  [34,]     1 18    2        13  0.01 #>  [35,]     1 19    2        14  0.01 #>  [36,]     1 20    2        15  0.01 #>  [37,]     1 21    2        16  0.01 #>  [38,]     1 22    2        17  0.01 #>  [39,]     1 23    2        18  0.01 #>  [40,]     1 24    2        19  0.01 #>  [41,]     1 25    2        20  0.01 #>  [42,]     1 26    2        21  0.01 #>  [43,]     1  3   14         1  0.01 #>  [44,]     1  4   14         2  0.01 #>  [45,]     1  5   14         3  0.01 #>  [46,]     1  6   14         4  0.01 #>  [47,]     1  7   14         5  0.01 #>  [48,]     1  8   14         6  0.01 #>  [49,]     1  9   14         7  0.01 #>  [50,]     1 10   14         8  0.01 #>  [51,]     1 11   14         9  0.01 #>  [52,]     1 12   14        10  0.01 #>  [53,]     1 13   14        11  0.01 #>  [54,]     1 16   14         1  0.01 #>  [55,]     1 17   14         2  0.01 #>  [56,]     1 18   14         3  0.01 #>  [57,]     1 19   14         4  0.01 #>  [58,]     1 20   14         5  0.01 #>  [59,]     1 21   14         6  0.01 #>  [60,]     1 22   14         7  0.01 #>  [61,]     1 23   14         8  0.01 #>  [62,]     1 24   14         9  0.01 #>  [63,]     1 25   14        10  0.01 #>  [64,]     1 26   14        11  0.01 #>  [65,]     1  4   15        12  0.01 #>  [66,]     1  5   15        13  0.01 #>  [67,]     1  6   15        14  0.01 #>  [68,]     1  7   15        15  0.01 #>  [69,]     1  8   15        16  0.01 #>  [70,]     1  9   15        17  0.01 #>  [71,]     1 10   15        18  0.01 #>  [72,]     1 11   15        19  0.01 #>  [73,]     1 12   15        20  0.01 #>  [74,]     1 13   15        21  0.01 #>  [75,]     1 17   15        12  0.01 #>  [76,]     1 18   15        13  0.01 #>  [77,]     1 19   15        14  0.01 #>  [78,]     1 20   15        15  0.01 #>  [79,]     1 21   15        16  0.01 #>  [80,]     1 22   15        17  0.01 #>  [81,]     1 23   15        18  0.01 #>  [82,]     1 24   15        19  0.01 #>  [83,]     1 25   15        20  0.01 #>  [84,]     1 26   15        21  0.01 #>  [85,]     2  1    1         0  1.00 #>  [86,]     2  2    2         0  1.00 #>  [87,]     2  3    3        22    NA #>  [88,]     2  4    4        22    NA #>  [89,]     2  5    5        22    NA #>  [90,]     2  6    6        22    NA #>  [91,]     2  7    7        22    NA #>  [92,]     2  8    8        22    NA #>  [93,]     2  9    9        22    NA #>  [94,]     2 10   10        22    NA #>  [95,]     2 11   11        22    NA #>  [96,]     2 12   12        22    NA #>  [97,]     2 13   13        22    NA #>  [98,]     2 14   14         0  1.00 #>  [99,]     2 15   15         0  1.00 #> [100,]     2 16   16        23    NA #> [101,]     2 17   17        23    NA #> [102,]     2 18   18        23    NA #> [103,]     2 19   19        23    NA #> [104,]     2 20   20        23    NA #> [105,]     2 21   21        23    NA #> [106,]     2 22   22        23    NA #> [107,]     2 23   23        23    NA #> [108,]     2 24   24        23    NA #> [109,]     2 25   25        23    NA #> [110,]     2 26   26        23    NA #>  #> $variances #>        to    from parameter #> 1   EOF_1   EOF_1         0 #> 2   EOF_2   EOF_2         0 #> 3 pollock pollock        22 #> 4     cod     cod        23 #>  #> $standard_deviations #> [1] \"unequal\" #>  #> attr(,\"class\") #> [1] \"eof_ram\""},{"path":"/reference/make_sem_ram.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a RAM (Reticular Action Model) from a SEM (structural equation model) — make_sem_ram","title":"Make a RAM (Reticular Action Model) from a SEM (structural equation model) — make_sem_ram","text":"make_sem_ram converts SEM arrow notation ram describing SEM parameters","code":""},{"path":"/reference/make_sem_ram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a RAM (Reticular Action Model) from a SEM (structural equation model) — make_sem_ram","text":"","code":"make_sem_ram(sem, variables, quiet = FALSE, covs = variables)"},{"path":"/reference/make_sem_ram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a RAM (Reticular Action Model) from a SEM (structural equation model) — make_sem_ram","text":"sem structural equation model structure, passed either specifyModel specifyEquations parsed control set path coefficients variance-covariance parameters variables character vector listing set variables quiet FALSE, default, number input lines reported     message printed suggesting specifyEquations cfa used. covs optional: character vector one elements, element   \tgiving string variable names, separated commas. Variances covariances   \tamong variables string added model. confirmatory   \tfactor analysis models specified via cfa, covs defaults   \tfactors model, thus specifying variances covariances among factors.   \tWarning: covs=\"x1, x2\" covs=c(\"x1\", \"x2\")   \tequivalent: covs=\"x1, x2\" specifies variance x1, variance   \tx2, covariance, covs=c(\"x1\", \"x2\") specifies   \tvariance x1 variance x2 covariance.","code":""},{"path":"/reference/make_sem_ram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a RAM (Reticular Action Model) from a SEM (structural equation model) — make_sem_ram","text":"S3-class \"sem_ram\" containing: model Output specifyEquations specifyModel defines paths parameters ram reticular action module (RAM) describing dependencies","code":""},{"path":"/reference/parse_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse path — parse_path","title":"Parse path — parse_path","text":"parse_path copied sem::parse.path","code":""},{"path":"/reference/parse_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse path — parse_path","text":"","code":"parse_path(path)"},{"path":"/reference/parse_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse path — parse_path","text":"path character string indicating one-headed two-headed path structural equation model","code":""},{"path":"/reference/parse_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse path — parse_path","text":"Tagged-list defining variables direction specified path coefficient","code":""},{"path":"/reference/parse_path.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parse path — parse_path","text":"Copied package sem licence GPL (>= 2) permission John Fox","code":""},{"path":"/reference/predict.tinyVAST.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict using vector autoregressive spatio-temporal model — predict.tinyVAST","title":"Predict using vector autoregressive spatio-temporal model — predict.tinyVAST","text":"Predicts values given new covariates using tinyVAST model","code":""},{"path":"/reference/predict.tinyVAST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict using vector autoregressive spatio-temporal model — predict.tinyVAST","text":"","code":"# S3 method for tinyVAST predict(   object,   newdata,   remove_origdata = FALSE,   what = c(\"mu_g\", \"p_g\", \"palpha_g\", \"pgamma_g\", \"pepsilon_g\", \"pomega_g\"),   se.fit = FALSE,   ... )"},{"path":"/reference/predict.tinyVAST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict using vector autoregressive spatio-temporal model — predict.tinyVAST","text":"object Output tinyVAST(). newdata New data-frame independent variables used predict response. remove_origdata Whether eliminate original data TMB object, thereby speeding TMB object construction.  However, also eliminates information random-effect variance, appropriate requesting predictive standard errors epsilon bias-correction. REPORTed object output, p_g linear predictor, mu_g inverse-linked transformed predictor. others additive components linear predictor. se.fit Calculate standard errors? ... used.","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. sdmTMB lognormal, tweedie","code":""},{"path":"/reference/reload_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Reload a previously fitted model — reload_model","title":"Reload a previously fitted model — reload_model","text":"reload_model allows user save fitted model, reload new R terminal, relink DLLs functions expected.","code":""},{"path":"/reference/reload_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reload a previously fitted model — reload_model","text":"","code":"reload_model(x, check_gradient = TRUE)"},{"path":"/reference/reload_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reload a previously fitted model — reload_model","text":"x Output tinyVAST, potentially DLLs linked check_gradient Whether check gradients reloaded model","code":""},{"path":"/reference/reload_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reload a previously fitted model — reload_model","text":"Output tinyVAST DLLs relinked","code":""},{"path":"/reference/reload_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reload a previously fitted model — reload_model","text":"","code":"if (FALSE) { # Run model fit = tinyVAST( ... ) saveRDS( object=fit, file=\"path_and_name.rds\" )  # Reload and relink fit_new = readRDS( file=\"path_and_name.rds\" ) fit_new = reload_model( x = fit_new ) }"},{"path":"/reference/residuals.tinyVAST.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate deviance or response residuals for tinyVAST — residuals.tinyVAST","title":"Calculate deviance or response residuals for tinyVAST — residuals.tinyVAST","text":"Calculate residuals","code":""},{"path":"/reference/residuals.tinyVAST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate deviance or response residuals for tinyVAST — residuals.tinyVAST","text":"","code":"# S3 method for tinyVAST residuals(object, type = c(\"deviance\", \"response\"), ...)"},{"path":"/reference/residuals.tinyVAST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate deviance or response residuals for tinyVAST — residuals.tinyVAST","text":"object Output tinyVAST() type type residuals compute (option \"deviance\" \"response\" now) ... Note used","code":""},{"path":"/reference/rmvnorm_prec.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Normal Random Deviates using Sparse Precision — rmvnorm_prec","title":"Multivariate Normal Random Deviates using Sparse Precision — rmvnorm_prec","text":"function provides random number generator multivariate normal distribution mean equal mean sparse precision matrix Q.","code":""},{"path":"/reference/rmvnorm_prec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Normal Random Deviates using Sparse Precision — rmvnorm_prec","text":"","code":"rmvnorm_prec(Q, n = 1, mean = rep(0, nrow(Q)))"},{"path":"/reference/rmvnorm_prec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Normal Random Deviates using Sparse Precision — rmvnorm_prec","text":"Q sparse precision (inverse-covariance) matrix. n number observations. mean mean vector.","code":""},{"path":"/reference/rmvnorm_prec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Normal Random Deviates using Sparse Precision — rmvnorm_prec","text":"matrix dimension length(mean) n, containing realized draws specified mean precision","code":""},{"path":"/reference/rotate_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Rotate factors to match Principal-Components Analysis — rotate_pca","title":"Rotate factors to match Principal-Components Analysis — rotate_pca","text":"Rotate lower-triangle loadings matrix order factors largest smallest variance.","code":""},{"path":"/reference/rotate_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rotate factors to match Principal-Components Analysis — rotate_pca","text":"","code":"rotate_pca(   L_tf,   x_sf = matrix(0, nrow = 0, ncol = ncol(L_tf)),   order = c(\"none\", \"increasing\", \"decreasing\") )"},{"path":"/reference/rotate_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rotate factors to match Principal-Components Analysis — rotate_pca","text":"L_tf Loadings matrix dimension \\(T \\times F\\). x_sf Spatial response dimensions \\(S \\times F\\). order Options resolving label-switching via reflecting factor achieve given order across dimension \\(T\\).","code":""},{"path":"/reference/rotate_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rotate factors to match Principal-Components Analysis — rotate_pca","text":"List containing rotated loadings L_tf, inverse-rotated response matrix x_sf, rotation H","code":""},{"path":"/reference/salmon_returns.html","id":null,"dir":"Reference","previous_headings":"","what":"North Pacific salmon returns — salmon_returns","title":"North Pacific salmon returns — salmon_returns","text":"Data used demonstrate test multivariate second-order autoregressive models using simultaneous autoregressive (SAR) process across regions. Data doi:10.1002/mcf2.10023","code":""},{"path":"/reference/salmon_returns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"North Pacific salmon returns — salmon_returns","text":"","code":"data(salmon_returns)"},{"path":"/reference/sample_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from predictive distribution of a variable — sample_variable","title":"Sample from predictive distribution of a variable — sample_variable","text":"sample_variable samples joint distribution random fixed effects approximate predictive distribution variable Using sample_fixed=TRUE (default) sample_variable propagates variance fixed random effects, using sample_fixed=FALSE . Sampling fixed effects sometimes cause numerical - overflow (.e., output values NA) cases variance parameters estimated imprecisely.  cases, multivariate normal approximation used poor representation tail probabilities, results samples implausibly high (negative) variances, associated random effects implausibly high magnitude.","code":""},{"path":"/reference/sample_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from predictive distribution of a variable — sample_variable","text":"","code":"sample_variable(   x,   variable_name = \"mu_i\",   n_samples = 100,   sample_fixed = TRUE,   seed = 123456 )"},{"path":"/reference/sample_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from predictive distribution of a variable — sample_variable","text":"x output \\code{tinyVAST()} variable_name name variable available report using Obj$report() parameters using Obj$env$parList() n_samples number samples joint predictive distribution fixed random effects.  Default 100, slow. sample_fixed whether sample fixed random effects, sample_fixed=TRUE default, just sample random effects, sample_fixed=FALSE seed integer used set random-number seed sampling variables, passed set.seed(.)","code":""},{"path":"/reference/sample_variable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from predictive distribution of a variable — sample_variable","text":"","code":"if (FALSE) { # Run model using selected inputs, but also with getJointPrecision=TRUE fit = tinyVAST( ...,     control = tinyVASTcontrol(getJointPrecision=TRUE) )  # Run sample_variable sample = sample_variable( x = fit,                           variable_name = \"mu_i\" ) }"},{"path":"/reference/sea_ice.html","id":null,"dir":"Reference","previous_headings":"","what":"Arctic September sea ice concentrations — sea_ice","title":"Arctic September sea ice concentrations — sea_ice","text":"Data used demonstrate test empirical orthogonal function generalized linear latent variable model (EOF-GLLVM)","code":""},{"path":"/reference/sea_ice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arctic September sea ice concentrations — sea_ice","text":"","code":"data(sea_ice)"},{"path":"/reference/sfnetwork_evaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct projection matrix for stream network — sfnetwork_evaluator","title":"Construct projection matrix for stream network — sfnetwork_evaluator","text":"Make sparse matrix project stream-network nodes user-supplied points","code":""},{"path":"/reference/sfnetwork_evaluator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct projection matrix for stream network — sfnetwork_evaluator","text":"","code":"sfnetwork_evaluator(stream, loc, tolerance = 0.01)"},{"path":"/reference/sfnetwork_evaluator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct projection matrix for stream network — sfnetwork_evaluator","text":"stream sfnetworks object representing stream network loc sf object representing points projected tolerance error-check tolerance","code":""},{"path":"/reference/sfnetwork_mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Make mesh for stream network — sfnetwork_mesh","title":"Make mesh for stream network — sfnetwork_mesh","text":"Make mesh stream network","code":""},{"path":"/reference/sfnetwork_mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make mesh for stream network — sfnetwork_mesh","text":"","code":"sfnetwork_mesh(stream)"},{"path":"/reference/sfnetwork_mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make mesh for stream network — sfnetwork_mesh","text":"stream sfnetworks object representing stream network","code":""},{"path":"/reference/simulate_sfnetwork.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate GMRF for stream network — simulate_sfnetwork","title":"Simulate GMRF for stream network — simulate_sfnetwork","text":"Simulate GMRF stream network","code":""},{"path":"/reference/simulate_sfnetwork.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate GMRF for stream network — simulate_sfnetwork","text":"","code":"simulate_sfnetwork(sfnetwork_mesh, theta, n = 1, what = c(\"samples\", \"Q\"))"},{"path":"/reference/simulate_sfnetwork.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate GMRF for stream network — simulate_sfnetwork","text":"sfnetwork_mesh Output sfnetwork_mesh theta Decorrelation rate n number simulated GMRFs Whether return simulated GMRF precision matrix","code":""},{"path":"/reference/summary.tinyVAST.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize tinyVAST — summary.tinyVAST","title":"summarize tinyVAST — summary.tinyVAST","text":"summarize parameters fitted tinyVAST","code":""},{"path":"/reference/summary.tinyVAST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize tinyVAST — summary.tinyVAST","text":"","code":"# S3 method for tinyVAST summary(object, what = c(\"sem\", \"dsem\"), ...)"},{"path":"/reference/summary.tinyVAST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize tinyVAST — summary.tinyVAST","text":"object Output tinyVAST() component summarize ... used","code":""},{"path":"/reference/summary.tinyVAST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"summarize tinyVAST — summary.tinyVAST","text":"tinyVAST includes \"arrow lag\" notation, specifies set path coefficients exogenous variance parameters estimated. Function fit estimates maximum likelihood value coefficients parameters maximizing log-marginal likelihood. However, many users want associate individual parameters standard errors path coefficients specified using \"arrow lag\" notation. task complicated models path coefficients variance parameters specified share single value priori, assigned name NA hence assumed fixed value priori (coefficients parameters assigned value standard error). summary function therefore compiles MLE coefficients (including duplicating values path coefficients assigned value) standard error estimates, outputs table associates user-supplied path parameter names. also outputs z-score p-value arising two-sided Wald test (.e. comparing estimate divided standard error standard normal distribution).","code":""},{"path":"/reference/tinyVAST.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit vector autoregressive spatio-temporal model — tinyVAST","title":"Fit vector autoregressive spatio-temporal model — tinyVAST","text":"Fits vector autoregressive spatio-temporal model using minimal feature-set widely used interface.","code":""},{"path":"/reference/tinyVAST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit vector autoregressive spatio-temporal model — tinyVAST","text":"","code":"tinyVAST(   formula,   data,   sem = NULL,   dsem = NULL,   family = gaussian(),   space_columns = c(\"x\", \"y\"),   spatial_graph = NULL,   time_column = \"time\",   times = NULL,   variable_column = \"var\",   variables = NULL,   distribution_column = \"dist\",   delta_options = list(delta_formula = ~1),   control = tinyVASTcontrol(),   ... )"},{"path":"/reference/tinyVAST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit vector autoregressive spatio-temporal model — tinyVAST","text":"formula Formula response left-hand-side predictors right-hand-side, parsed mgcv hence allowing s(.) splines offset(.) offset. data Data-frame predictor, response, offset variables.  Also includes variables specify space, time, variables, distribution samples, identified arguments variable_column, time_column, space_columns, distribution_column. sem Specification structural equation model structure constructing space-variable interaction. sem=NULL disables space-variable interaction; see make_sem_ram(). dsem Specification time-series structural equation model structure including lagged simultaneous effects constructing space-variable interaction. dsem=NULL disables space-variable interaction; see make_dsem_ram()  make_eof_ram(). family function returning class family, including gaussian(), lognormal(), tweedie(). Alternatively, can named list functions, names match levels data$distribution_column allow different families row data. Delta model families possible. See Families, space_columns string character vector indicates column(s) data indicating location sample. spatial_graph igraph object, space_columns string levels matching names vertices object. spatial_graph fmesher sfnetwork object, space_columns character vector indicating columns data coordinates sample. spatial_graph Object represents spatial relationships, either using fmesher::fm_mesh_2d() apply SPDE method, igraph::make_empty_graph() independent time-series, igraph::make_graph() apply simultaneous autoregressive (SAR) process, sfnetwork_mesh() stream networks, NULL specify single site. time_column character string indicating column data listing time-interval sample, set times argument times. times integer vector listing set times order. times=NULL, filled vector integers minimum maximum value data$time. variable_column character string indicating column data listing variable sample, set times argument variables. variables character vector listing set variables. variables=NULL, filled unique values data$variable_columns. distribution_column character string indicating column data listing distribution sample, set names argument family. variables=NULL, filled unique values data$variables. delta_options named list slots delta_formula, delta_sem, delta_dsem. follow format family, sem, dsem, specify options second linear predictor delta model, used (estimable) delta family used samples. control Output tinyVASTcontrol(), used define user settings. ... used.","code":""},{"path":"/reference/tinyVAST.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit vector autoregressive spatio-temporal model — tinyVAST","text":"tinyVAST includes four basic inputs specify model structure: formula specifies covariates splines Generalized Additive Model; dsem specifies interactions among variables time, constructing space-time-variable interaction. sem specifies interactions among variables time, constructing space-variable interaction. spatial_graph specifies spatial correlations default dsem=NULL turns multivariate temporal indexing, spatial_graph ignored, model collapses standard model using gam.  specify univeriate spatial model, user must specify spatial_graph dsem=\"\", latter parsed include single exogenous variance single variable","code":""},{"path":"/reference/tinyVAST.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit vector autoregressive spatio-temporal model — tinyVAST","text":"","code":"# Simulate a 2D AR1 spatial process with a cyclic confounder w n_x = n_y = 25 n_w = 10 R_xx = exp(-0.4 * abs(outer(1:n_x, 1:n_x, FUN=\"-\")) ) R_yy = exp(-0.4 * abs(outer(1:n_y, 1:n_y, FUN=\"-\")) ) z = mvtnorm::rmvnorm(1, sigma=kronecker(R_xx,R_yy) )  # Simulate nuissance parameter z from oscillatory (day-night) process w = sample(1:n_w, replace=TRUE, size=length(z)) Data = data.frame( expand.grid(x=1:n_x, y=1:n_y), w=w, z=as.vector(z) + cos(w/n_w*2*pi)) Data$n = Data$z + rnorm(nrow(Data), sd=1)  # Add columns for multivariate and temporal dimensions Data$var = \"n\"  # make mesh mesh = fmesher::fm_mesh_2d( Data[,c('x','y')], n=100 )  # fit model out = tinyVAST( data = Data,                 formula = n ~ s(w),                 spatial_graph = mesh,                 sem = \"n <-> n, sd_n\" )"},{"path":"/reference/tinyVASTcontrol.html","id":null,"dir":"Reference","previous_headings":"","what":"Control parameters for tinyVAST — tinyVASTcontrol","title":"Control parameters for tinyVAST — tinyVASTcontrol","text":"Control parameters tinyVAST","code":""},{"path":"/reference/tinyVASTcontrol.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control parameters for tinyVAST — tinyVASTcontrol","text":"","code":"tinyVASTcontrol(   nlminb_loops = 1,   newton_loops = 0,   eval.max = 1000,   iter.max = 1000,   getsd = TRUE,   silent = getOption(\"tinyVAST.silent\", TRUE),   trace = getOption(\"tinyVAST.trace\", 0),   verbose = getOption(\"tinyVAST.verbose\", FALSE),   profile = c(),   tmb_par = NULL,   gmrf_parameterization = c(\"separable\", \"projection\"),   estimate_delta0 = FALSE,   getJointPrecision = FALSE )"},{"path":"/reference/tinyVASTcontrol.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control parameters for tinyVAST — tinyVASTcontrol","text":"nlminb_loops Integer number times call stats::nlminb(). newton_loops Integer number Newton steps running stats::nlminb(). eval.max Maximum number evaluations objective function allowed. Passed control stats::nlminb(). iter.max Maximum number iterations allowed. Passed control stats::nlminb(). getsd Boolean indicating whether call TMB::sdreport() silent Disable terminal output inner optimizer? trace Parameter values printed every trace iteration outer optimizer. Passed control stats::nlminb(). verbose Output additional messages model steps fitting? profile Parameters profile likelihood (subset appended random Laplace approximation disabled). tmb_par list parameters starting values, shape identical tinyVAST(...)$internal$parlist gmrf_parameterization Parameterization use Gaussian Markov random field, default separable constructs full-rank separable precision matrix, alternative projection constructs full-rank IID precision variables time, projects using inverse-cholesky precision, projection allows rank-deficient covariance. estimate_delta0 Estimate delta model? getJointPrecision whether get joint precision matrix.  Passed sdreport.","code":""},{"path":"/reference/vcov.tinyVAST.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Variance-Covariance Matrix — vcov.tinyVAST","title":"Extract Variance-Covariance Matrix — vcov.tinyVAST","text":"extract covariance fixed effects, fixed random effects.","code":""},{"path":"/reference/vcov.tinyVAST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Variance-Covariance Matrix — vcov.tinyVAST","text":"","code":"# S3 method for tinyVAST vcov(object, which = c(\"fixed\", \"random\", \"both\"), ...)"},{"path":"/reference/vcov.tinyVAST.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Variance-Covariance Matrix — vcov.tinyVAST","text":"object output tinyVAST() whether extract covariance among fixed effects, random effects, ... ignored, method compatibility","code":""},{"path":"/news/index.html","id":"tinyvast-040","dir":"Changelog","previous_headings":"","what":"tinyVAST 0.4.0","title":"tinyVAST 0.4.0","text":"Adding code simulation residuals, examples vignettes","code":""},{"path":"/news/index.html","id":"tinyvast-030","dir":"Changelog","previous_headings":"","what":"tinyVAST 0.3.0","title":"tinyVAST 0.3.0","text":"Adding sdmTMB dependency, importing family options Adding vignette joint analysis condition density","code":""},{"path":"/news/index.html","id":"tinyvast-020","dir":"Changelog","previous_headings":"","what":"tinyVAST 0.2.0","title":"tinyVAST 0.2.0","text":"Add option specify covariance SEM DSEM notation","code":""},{"path":"/news/index.html","id":"tinyvast-010","dir":"Changelog","previous_headings":"","what":"tinyVAST 0.1.0","title":"tinyVAST 0.1.0","text":"Initial public alpha release","code":""}]
